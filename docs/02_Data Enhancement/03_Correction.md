---
sidebar_position: 3
---

# üßπ M√≥dulo de Correcci√≥n de Escritura de Datos

Este m√≥dulo forma parte del flujo integral de *data enhancement* y tiene como objetivo principal **detectar y corregir errores en la escritura de datos**, especialmente en columnas categ√≥ricas y num√©ricas que han sido ingresadas de forma inconsistente.

---

## üéØ Objetivo general

Detectar y corregir autom√°ticamente errores comunes en la escritura de datos, como:

- Errores ortogr√°ficos en categor√≠as (`"fememino"` ‚Üí `"femenino"`)
- Valores mal escritos en n√∫meros (`"1.500,00"` ‚Üí `1500.00`)
- Variaciones de texto (`"MASCULINO"` ‚Üí `"masculino"`)
- Valores vac√≠os o inv√°lidos

---

## üîç Funcionalidades clave

- **Normalizaci√≥n de texto**: min√∫sculas, eliminaci√≥n de espacios extra
- **Correcci√≥n inteligente**: usa similitud (`fuzzywuzzy`) para encontrar la opci√≥n m√°s cercana a partir de listas blancas
- **Limpieza de valores num√©ricos**: detecta patrones comunes mal formateados y los convierte a `float`
- **Registro de cambios**: muestra qu√© filas se corrigieron y cu√°nto cambi√≥ cada columna

---

## üìä Tipos de correcci√≥n

| Tipo | Descripci√≥n |
|------|-------------|
| **Texto categ√≥rico** | Se corrige usando listas blancas y similitud |
| **Valores num√©ricos** | Se limpian errores frecuentes y se convierten a float |

---
## üìÅ Estructura del Paquete

1. **`text_normalizer.py`**: Clase principal: TextNormalizer 
2. **`report_printer.py`**: Genera informe de cambios
3. **`rule_engine.py`**: Opcional: para reglas personalizadas
4. **`error_simulator.py`**: (opcional) Simular errores para pruebas 

---
## üß© Flujo del m√≥dulo

### Paso 1: Definici√≥n de las columnas que ser√°n procesadas por el m√≥dulo

El usuario define cu√°les son las columnas que deben ser procesadas por el m√≥dulo. Estas pueden ser:

- Columnas categ√≥ricas (ej: genero, ubi_geografica, estado_civil)
- Columnas num√©ricas que podr√≠an estar mal escritas (ej: ingresos, score)

```python
LISTAS_BLANCAS = {
    'genero': ['femenino', 'masculino'],
    'ubi_geografica': ['urbano', 'rural', 'extranjero'],
    'preferencia_canal': ['banca_app', 'banca_f√≠sica', 'banca_linea']
}
```
### Paso 2: Normalizaci√≥n y correcci√≥n de texto
Se recorren las columnas definidas como relevantes y se aplica:
- Para columnas **categ√≥ricas :**
  - Se convierte todo a min√∫sculas y sin espacios extra
  - Se compara cada valor contra una lista blanca
  - Si hay similitud alta (>80% con fuzzywuzzy), se corrige al valor v√°lido m√°s cercano
  - Si no hay coincidencia clara, se marca como NaN
  
- Para columnas **num√©ricas :**
  - Se eliminan caracteres especiales (ej: letras o s√≠mbolos en n√∫meros)
  - Se corrigen formatos comunes ("1,500.34" ‚Üí "1500.34")
  - Se convierten a float o int seg√∫n corresponda

### Paso 3: Registro de cambios realizados
Se genera un registro (log) para mostrar qu√© filas fueron corregidas y qu√© columna tuvo cambios.

**Visualizaci√≥n del log üëÄ**

| Columnas | Cambios Realizados |
|----------|--------------------|
| `genero` | 3|
| `ingresos`| 2|
| `score` | 5|

### Paso 4: Resultado final
El m√≥dulo devuelve:
- Un DataFrame con las columnas corregidas
- Un registro detallado de los cambios
- Opcionalmente, columnas nuevas con sufijo _corregido para comparar antes/despu√©s

---
## üß™ Ejemplo de uso
---

```python
from CorreccionEscritura.text_normalizer import TextNormalizer
from CorreccionEscritura.report_printer import WritingReportPrinter
from CorreccionEscritura.error_simulator import introducir_errores_escritura

# Cargar datos
ruta = r'C:\Users\Joyssie\Downloads\data.csv'
df = pd.read_csv(ruta)

# Simular errores (opcional, para testing)
columnas_categoricas = list(LISTAS_BLANCAS.keys())
df_con_errores = introducir_errores_escritura(df, columnas_categoricas)

# Iniciar proceso de correcci√≥n
normalizer = TextNormalizer(df_con_errores)
df_corregido = normalizer.aplicar_correcciones()

# Imprimir resultados
printer = WritingReportPrinter(normalizer)
printer.imprimir_resumen()

```