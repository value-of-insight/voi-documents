---
sidebar_position: 1
---

# üîç M√≥dulo de Detecci√≥n y Manejo de Duplicados

Este m√≥dulo forma parte del flujo integral de *data enhancement* y tiene como objetivo principal **detectar y resolver duplicados en un conjunto de datos**, priorizando la conservaci√≥n del registro m√°s representativo por cliente.

> ‚ö†Ô∏è Este m√≥dulo debe ejecutarse **despu√©s de imputar missings, corregir tipos de dato y normalizar texto**, ya que esos pasos son fundamentales para evitar falsos positivos o errores en la comparaci√≥n de registros.

---

## üéØ Objetivo general

Detectar clientes con m√∫ltiples registros (duplicados) y elegir **el m√°s representativo** seg√∫n su perfil num√©rico o categ√≥rico. Esto permite:

- Mejor calidad de datos para modelos predictivos
- Reducir sesgos causados por datos redundantes
- Mantener solo una fila por cliente sin perder informaci√≥n relevante

---

## üß† Funcionalidades clave

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| **Detecci√≥n autom√°tica** | Identifica filas duplicadas bas√°ndose en una columna clave (`ID_Cliente`, `dni`, etc.) |
| **Decisi√≥n inteligente** | Selecciona el mejor registro usando distancia euclidiana (si grupo es categ√≥rico) o proximidad al promedio (si grupo es num√©rico) |
| **Registro claro** | Genera un informe con estad√≠sticas de duplicados encontrados y eliminados |
| **Modularidad** | F√°cil de integrar con otros m√≥dulos del flujo |

---
## üìÅ Estructura del Paquete

1. **`duplicate_detector.py`**: Clase principal - DuplicateDetector
2. **`duplicate_reporter.py`**: Generador de informes

---

## üß© Flujo del m√≥dulo

### Paso 1: Cargar DataFrame ya limpio
El dataset debe haber pasado por:
- Imputaci√≥n de missings
- Correcci√≥n de tipo de dato
- Normalizaci√≥n de texto

### Paso 2: Definir columnas clave

- `id_col`: identificador √∫nico del cliente (ej: `ID_Cliente`)
- `grupo_col`: variable usada para evaluar el perfil del cliente (ej: `Distrito_Residencia`, `Edad`)
- `variables_numericas`: columnas usadas para comparar perfiles (ej: `Ingresos`, `Score`, `Saldo`)

Ejemplo:

```python
id_cliente = 'ID_Cliente'
grupo_seleccion = 'Distrito_Residencia'
variables_numericas = ['Edad', 'Ingresos', 'Score', 'Saldo']
```

### Paso 3: Detectar duplicados por cliente
Se agrupa por id_col y se buscan clientes con m√°s de un registro.

### Paso 4: Resolver qu√© fila conservar
- Si grupo_col es categ√≥rico ‚Üí se compara cada fila contra el perfil promedio del grupo
- Si grupo_col es num√©rico ‚Üí se elige el registro m√°s cercano al promedio general

### Paso 5: Registrar cambios realizados
Se genera un resumen con:
- Total de registros procesados
- Clientes √∫nicos
- N√∫mero de duplicados encontrados y eliminados
- Ejemplo de datos filtrados

---
## üß™ Ejemplo de uso
---

```python
from DeteccionDuplicados.duplicate_detector import DuplicateDetector
from DeteccionDuplicados.duplicate_reporter import DuplicateReporter

# Cargar datos
ruta = r'C:\Users\Joyssie\Downloads\data.csv'
df = pd.read_csv(ruta)

# Definir columnas clave
id_cliente = 'ID_Cliente'
grupo_seleccion = 'Distrito_Residencia'
variables_numericas = ['Edad', 'Ingresos', 'Score', 'Saldo']

# Iniciar proceso de detecci√≥n
detector = DuplicateDetector(df, id_cliente, grupo_seleccion, variables_numericas)
df_limpio, resumen = detector.detectar_y_manejar_duplicados()

# Imprimir resultados
reporter = DuplicateReporter(detector)
reporter.imprimir_resumen()

```